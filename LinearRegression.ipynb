{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "- Used for finding linear relationship between target and one or more predictors.\n",
    "- Line equation: <strong> y = wx + b</strong>\n",
    "\n",
    "### Cost Function\n",
    "\n",
    "<h4><em>MSE = (1/n) * Σ(actual – forecast)2</em></h4>\n",
    "\n",
    "where:\n",
    "- Σ – a fancy symbol that means “sum”\n",
    "- n – sample size\n",
    "- actual – the actual data value\n",
    "- forecast – the forecasted data value\n",
    "\n",
    "\n",
    "### Gradient Descent\n",
    "- First-order iterative optimization algorithm for finding a local minimum of a differentiable function. The idea is to take repeated steps in the opposite direction of the gradient (or approximate gradient) of the function at the current point, because this is the direction of steepest descent. \n",
    "\n",
    "<img src='https://th.bing.com/th/id/R.34cfcc099da15ce73cfeba407a183543?rik=NkWoKbOl0MULww&riu=http%3a%2f%2fwww.big-data.tips%2fwp-content%2fuploads%2f2016%2f06%2fgradient-types.jpg&ehk=%2f%2bSrxS0IAcjZeSlFD5FtwB9NHF2M2AqBB5aDnaQKUac%3d&risl=&pid=ImgRaw&r=0' height='10px' width='700px'/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
